# TOMAS-LLM Default Configuration

# ============================================================
# 数据路径配置
# ============================================================
data:
  tool_registry_path: "data/tool_registry/tools.json"
  profiling_path: "data/profiling/profiling.csv"
  
# ============================================================
# LLM 配置 (Qwen2.5-7B for production)
# ============================================================
llm:
  model:
    name: "Qwen/Qwen2.5-7B-Instruct"  # Production model
    device: "cuda"  # Use GPU for production
    dtype: "bfloat16"  # BF16 for efficiency
    use_flash_attn: true  # Flash attention for speed
    trust_remote_code: true
    load_in_8bit: false  # Set true for memory-constrained GPU
    load_in_4bit: false  # Set true for very limited memory
  
  # Context Projector (投影context到LLM维度)
  context_projector:
    llm_hidden_dim: 3584  # Qwen2.5-7B hidden dimension
    temporal_dim: 256     # v_temporal from Section 2.4
    task_dim: 896         # Task embedding from Section 2.1  
    tool_dim: 1024        # Tool encoding from Section 1.5
    num_temporal_tokens: 1   # Number of temporal prefix tokens
    num_task_tokens: 1       # Number of task prefix tokens
    dropout: 0.1
  
  # Generation settings
  generation:
    max_new_tokens: 1024
    temperature: 0.7
    top_p: 0.9
    do_sample: true

# ============================================================
# 模型配置 (Legacy - kept for backward compatibility)
# ============================================================
model:
  # LLM Backbone
  backbone:
    name: "Qwen/Qwen2.5-7B"
    device: "cuda"  # "cuda" or "cpu"
    dtype: "bfloat16"  # "float32", "float16", "bfloat16"
    use_flash_attention: true
  
  # User Task Encoder (用户任务描述编码)
  task_encoder:
    max_length: 512  # 任务描述最大token长度
    use_pretrained_embeddings: true  # 使用预训练embedding（与LLM共享）
    pooling_method: "mean"  # 池化方法: mean, max, cls, last
  
  # Tool Encoder (Stream A) 维度配置
  tool_encoder:
    d_tool: 768  # 工具语义向量维度
    max_desc_length: 256  # 工具描述最大token长度
  
  # Resource MLP (Stream B) 维度配置
  resource_mlp:
    d_resource: 256  # 资源画像投影维度
    hidden_dim: 512  # MLP隐藏层维度
    input_features: 6  # [input_size, cpu_core, cpu_mem_gb, gpu_sm, gpu_mem_gb, latency_ms]
    dropout: 0.0  # Dropout probability (0.0 = no dropout)
    use_batch_norm: false  # Whether to use batch normalization
  
  # Multi-head Self-Attention (工具集合融合)
  tool_attention:
    num_heads: 8
    num_layers: 1
    dropout: 0.1
  
  # Temporal Encoder (1D-CNN)
  temporal_encoder:
    in_channels: 4  # [cpu_free_cores, cpu_free_memory, gpu_free_sm_ratio, gpu_free_mem_gb]
    out_channels: 128
    kernel_sizes: [3, 5, 7]  # 多尺度卷积核
    d_temporal: 256  # 时序特征向量维度
  
  # Latency Prediction Module
  latency_predictor:
    enabled: false  # Naive模式：使用固定值
    mode: "fixed"  # "fixed", "rule_based", "learned"
    fixed_t_inf_ms: 500  # 固定推理延迟（毫秒）
    enable_learning: false  # 是否启用学习型预测器
    hidden_dim: 128  # 学习型预测器隐藏层维度
    use_in_planning: true  # 是否在规划中考虑延迟
  
  # Output Heads
  output_heads:
    # Tool Classifier
    tool_classifier:
      hidden_dim: 512
    
    # Resource Regressor
    resource_regressor:
      hidden_dim: 512
      output_features: 4  # [cpu_core, cpu_mem_gb, gpu_sm, gpu_mem_gb]
      activation: "relu"

# ============================================================
# Output Heads (Section 4.x - Right Panel)
# ============================================================
output_heads:
  # TokenTypeGate
  token_gate:
    vocab_size: 151936      # Qwen2.5 vocab size
    use_learned_gate: false # Use rule-based routing
  
  # ToolClassifier (Path B)
  tool_classifier:
    num_tools: 50           # Production: 50 tools
    tool_dim: 1024          # Tool embedding dimension
    use_attention: true     # Use multi-head attention pooling
    dropout: 0.1
  
  # ResourceRegressor (Path B)
  resource_regressor:
    temporal_dim: 256       # From Section 2.4 TemporalEncoder
    dropout: 0.1
    use_constraint: true    # Enforce resource constraints
    use_normalization: true # Use normalization for stable training
    
    # Normalization statistics (computed from training data)
    resource_stats:
      cpu_core: [8.0, 4.0]      # [mean, std]
      cpu_mem_gb: [32.0, 16.0]
      gpu_sm: [20.0, 10.0]
      gpu_mem_gb: [8.0, 4.0]
    
    # Resource limits (for clamping)
    default_max_resources:
      cpu_core: 64.0
      cpu_mem_gb: 256.0
      gpu_sm: 128.0
      gpu_mem_gb: 80.0

# ============================================================
# 训练配置
# ============================================================
training:
  batch_size: 4
  num_epochs: 10
  learning_rate: 1.0e-4
  weight_decay: 0.01
  warmup_steps: 100
  gradient_accumulation_steps: 4
  max_grad_norm: 1.0
  
  # 训练策略
  strategy: "freeze_backbone"  # "freeze_backbone", "lora", "full_finetune"
  
  # LoRA 配置（如果使用）
  lora:
    r: 16
    lora_alpha: 32
    lora_dropout: 0.05
    target_modules: ["q_proj", "v_proj"]
  
  # 损失函数权重
  loss_weights:
    tool_classification: 1.0
    resource_regression: 1.0
    feasibility_penalty: 0.5  # 超配惩罚
  
  # Checkpoint
  checkpoint_dir: "checkpoints"
  save_steps: 500
  eval_steps: 100

# ============================================================
# 推理配置
# ============================================================
inference:
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  do_sample: true
  
  # 资源约束裁剪
  resource_clipping:
    enabled: true
    max_cpu_cores: 32
    max_cpu_mem_gb: 128
    max_gpu_sm: 100  # 百分比
    max_gpu_mem_gb: 80

# ============================================================
# Runtime 配置
# ============================================================
runtime:
  # 系统资源快照
  timeline:
    prediction_window_sec: 60  # 预测未来60秒的资源曲线
    time_granularity_ms: 100  # 时间粒度100ms
    
  # Naive 固定曲线模拟（最小原型）
  naive_mode:
    enabled: true
    fixed_cpu_free_cores: [8, 8, 8, 8, 16, 16, 16, 16]  # 模拟8核->16核变化
    fixed_gpu_free_sm_ratio: [0.5, 0.5, 0.5, 0.8, 0.8, 0.8, 1.0, 1.0]
    fixed_gpu_free_mem_gb: [40, 40, 40, 60, 60, 60, 80, 80]

# ============================================================
# 评估配置
# ============================================================
evaluation:
  metrics:
    - "tool_accuracy"
    - "resource_mae"
    - "resource_mape"
    - "feasibility_rate"
    - "plan_parse_success_rate"
  
  test_data_path: "data/test_samples.json"

# ============================================================
# 日志配置
# ============================================================
logging:
  level: "INFO"  # "DEBUG", "INFO", "WARNING", "ERROR"
  log_dir: "logs"
  log_to_file: true

# ============================================================
# 特殊 Token 定义
# ============================================================
special_tokens:
  tool_plan_start: "<TOOL_PLAN>"
  tool_id: "<TOOL_ID>"
  resource_cfg: "<RESOURCE_CFG>"
  tool_plan_end: "</TOOL_PLAN>"
